## ğŸ” Web RAG Chatbot

An end-to-end Retrieval-Augmented Generation (RAG) chatbot built with:

ğŸŒ Firecrawl â†’ Crawl and extract website content

ğŸ§  ChromaDB â†’ Vector database for storing embeddings

âš¡ Ollama (local LLM) â†’ Answer user queries with local/self-hosted models (e.g., Mistral, Llama 3)

ğŸ’¬ Chainlit â†’ Chat UI for interacting with the bot

This project lets you crawl websites â†’ embed content â†’ ask questions â†’ get grounded answers via a simple web interface.

---

## âœ¨ Features

ğŸ” Crawl any website with Firecrawl

ğŸ“¦ Store embeddings locally in ChromaDB

ğŸ–¥ï¸ Use Ollama for both embeddings (nomic-embed-text) and LLM inference (mistral, llama3, etc.)

ğŸ’¬ Chat with your documents in Chainlit UI

ğŸ”„ Reset & re-ingest data easily

---
## ğŸ“‚ Project Structure

```
web-rag-chatbot/
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ firecrawl_crawl.py
â”‚   â”œâ”€â”€ ingest.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ rag_backend/
â”‚   â”œâ”€â”€ app.py                 # chainlit entry / web UI integration
â”‚   â”œâ”€â”€ rag.py                 # retrieval + LLM orchestration
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ chroma/                    # optional: scripts to manage chroma
â”‚   â””â”€â”€ reset_chroma.py
â”œâ”€â”€ docker-compose.yml         # optional: run chroma (if using server) / chainlit
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

```
